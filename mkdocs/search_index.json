{
    "docs": [
        {
            "location": "/", 
            "text": "TaylorSeries.jl\n\n\nA \nJulia\n package for Taylor expansions in one or more independent variables.\n\n\n\n\nAuthors\n\n\n\n\nLuis Benet\n, Instituto de Ciencias F\u00edsicas,\nUniversidad Nacional Aut\u00f3noma de M\u00e9xico (UNAM)\n\n\nDavid P. Sanders\n, Facultad de Ciencias,\nUniversidad Nacional Aut\u00f3noma de M\u00e9xico (UNAM)\n\n\n\n\nComments, suggestions and additions are welcome and appreciated.\n\n\nInstallation\n\n\nTaylorSeries.jl is a \nregistered package\n, and is\nsimply installed by running\n\n\njulia\n Pkg.add(\nTaylorSeries\n)\n\n\n\n\nLicense\n\n\nTaylorSeries is licensed under the MIT \"Expat\" license; see\n\nLICENSE\n for\nthe full license text.\n\n\nRelated packages\n\n\n\n\nPolynomials.jl\n: Polynomial\nmanipulations\n\n\nPowerSeries.jl\n: Truncated\npower series for Julia\n\n\nMultiPoly.jl\n Sparse\nmultivariate polynomials in Julia\n\n\n\n\nReferences\n\n\n\n\nW. Tucker, \nValidated Numerics: A Short Introduction to Rigorous\nComputations\n, Princeton University Press (2011).\n\n\nA. Haro, \nAutomatic differentiation methods in computational dynamical\nsystems: Invariant manifolds and normal forms of vector fields at fixed points\n,\n\npreprint\n.\n\n\n\n\nAcknowledgments\n\n\nThis project began (using Python) during a Masters' course in the postgraduate\nprograms in Physics and in Mathematics at UNAM, during the second half of 2013.\nWe thank the participants of the course for putting up with the half-baked\nmaterial and contributing energy and ideas.\n\n\nWe acknowledge financial support from DGAPA-UNAM PAPIME grants PE-105911 and\nPE-107114, and PAPIIT grant IG-101113. LB acknowledges support through a\n\nC\u00e1tedra Moshinsky\n (2013).", 
            "title": "Home"
        }, 
        {
            "location": "/#taylorseriesjl", 
            "text": "A  Julia  package for Taylor expansions in one or more independent variables.   Authors   Luis Benet , Instituto de Ciencias F\u00edsicas,\nUniversidad Nacional Aut\u00f3noma de M\u00e9xico (UNAM)  David P. Sanders , Facultad de Ciencias,\nUniversidad Nacional Aut\u00f3noma de M\u00e9xico (UNAM)   Comments, suggestions and additions are welcome and appreciated.  Installation  TaylorSeries.jl is a  registered package , and is\nsimply installed by running  julia  Pkg.add( TaylorSeries )  License  TaylorSeries is licensed under the MIT \"Expat\" license; see LICENSE  for\nthe full license text.  Related packages   Polynomials.jl : Polynomial\nmanipulations  PowerSeries.jl : Truncated\npower series for Julia  MultiPoly.jl  Sparse\nmultivariate polynomials in Julia   References   W. Tucker,  Validated Numerics: A Short Introduction to Rigorous\nComputations , Princeton University Press (2011).  A. Haro,  Automatic differentiation methods in computational dynamical\nsystems: Invariant manifolds and normal forms of vector fields at fixed points , preprint .   Acknowledgments  This project began (using Python) during a Masters' course in the postgraduate\nprograms in Physics and in Mathematics at UNAM, during the second half of 2013.\nWe thank the participants of the course for putting up with the half-baked\nmaterial and contributing energy and ideas.  We acknowledge financial support from DGAPA-UNAM PAPIME grants PE-105911 and\nPE-107114, and PAPIIT grant IG-101113. LB acknowledges support through a C\u00e1tedra Moshinsky  (2013).", 
            "title": "TaylorSeries.jl"
        }, 
        {
            "location": "/background/", 
            "text": "MathJax.Hub.Config({\n    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n  });\n  MathJax.Hub.Config({\n    TeX: { extensions: [\"AMSmath.js\", \"AMSsymbols.js\", \"autobold.js\", \"autoload-all.js\"] }\n  });\n  MathJax.Hub.Config({\n    tex2jax: {\n      inlineMath: [['$','$'], ['\\\\(','\\\\)']],\n      processEscapes: true\n    }\n  });\n\n\n\n\n\n\n\n\n\nBackground\n\n\n\n\nIntroduction\n\n\nTaylorSeries.jl\n is an implementation\nof high-order\n\nautomatic differentiation\n,\nas presented in the book by W. Tucker \n[1]\n. The general\nidea is the following.\n\n\nThe Taylor series expansion of an analytical function\n$f(t)$ with \none\n independent variable $t$ around $t_0$ can be written as\n\\begin{equation}\nf(t) = f_0 + f_1 (t-t_0) + f_2 (t-t_0)^2 + \\cdots + f_k (t-t_0)^k + \\cdots,\n\\end{equation}\nwhere $f_0=f(t_0)$, and the Taylor coefficients $f_k = f_k(t_0)$ are the\n$k$-th \nnormalized derivatives\n at $t_0$:\n\\begin{equation}\nf_k = \\frac{1}{k!} \\frac{{\\rm d}^k f} {{\\rm d} t^k}(t_0).\n\\end{equation}\nThus, computing the high-order derivatives of $f(x)$ is equivalent to computing\nits Taylor expansion.\n\n\nIn the case of \nmany\n independent variables the same statements hold, though\nthings become more subtle. Following Alex Haro's approach\n\n[2]\n, the Taylor\nexpansion is an infinite sum of \nhomogeneous polynomials\n in the $d$ independent\nvariables $x_1, x_2, \\dots, x_d$, which takes the form\n\\begin{equation}\nf_k (\\mathbf{x_0}) = \\sum_{m_1+\\cdots+m_d = k} f_{m_1,\\dots,m_d}\n(x_1-x_{0_1})^{m_1}\n\\cdots (x_d-x_{0_d})^{m_d} =\n\\sum_{|\\mathbf{m}|=k} f_\\mathbf{m} (\\mathbf{x}-\\mathbf{x_0})^\\mathbf{m}.\n\\end{equation}\nHere, $\\mathbf{m}\\in \\mathbb{N}^d$ is a multi-index of the $k$-th order\nhomogeneous polynomial and $\\mathbf{x}=(x_1,x_2,\\ldots,x_d)$ are the\n$d$ independent variables.\n\n\nIn both cases, a Taylor series expansion can be represented by a\nvector containing\nits coefficients. The difference between the cases of one or more independent variables\nis that the\ncoefficients are real or complex numbers in the former case, but homogeneous polynomials\nin the latter case. This motivates\nthe construction of the \nTaylor\n and \nTaylorN\n types, described later.\n\n\nArithmetic operations\n\n\nArithmetic operations involving Taylor series can be expressed as\noperations on the coefficients:\n\\begin{eqnarray}\n(f(x) \\pm g(x))_k \n = \n f_k \\pm g_k \\, , \\\\\n\\label{eq:multT}\n(f(x) \\cdot g(x))_k \n = \n \\sum_{i=0}^k f_i \\, g_{k-i} \\, ,\\\\\n\\Big(\\frac{f(x)}{g(x)}\\Big)_k \n = \n \\frac{1}{g_0} \\Big[ f_k -\n\\sum_{i=0}^{k-1} \\big(\\frac{f(x)}{g(x)}\\big)_i \\, g_{k-i} \\Big]\\, .\\\\\n\\end{eqnarray}\n\n\nEquation (\\ref{eq:multT}) corresponds to a convolution.\n\n\nElementary functions of polynomials\n\n\nConsider a function $y(t)$ that satisfies the ordinary differential equation\n$\\dot{y} = f(y)$, $y(t_0)=y_0$, where $t$ is the independent variable.\nWriting $y(t)$ and $f(t)$ as Taylor polynomials of $t$, substituting these in the\ndifferential equation and equating equal powers of\nthe independent variable leads to the recursion relation\n\\begin{equation}\n\\label{eq:rec}\ny_{n+1} = \\frac{f_n}{n+1}.\n\\end{equation}\nEquation (\\ref{eq:rec}), together with the corresponding initial condition, defines a recurrence relation\nfor the Taylor coefficients of $y(t)$ around $t_0$. For more independent\nvariables, using the chain rule for the \nradial derivative\n\nyields recurrence relations for the homogeneous polynomial coefficients\nof the function; see \n[2]\n.\n\n\nThe following are  examples of elementary functions constructed by\nsuch recurrence relations:\n\n\n\\begin{eqnarray}\np(t)=(f(t))^\\alpha , \\qquad \n\n  p_k \n = \\frac{1}{k \\, f_0}\\sum_{j=0}^{k-1}\\big( \\alpha(k-j)-j\\big)\n  \\, f_{k-j} \\, p_j; \\\\\ne(t) = \\exp(t) , \\qquad \n\n  e_k \n = \\frac{1}{k}\\sum_{j=0}^{k-1} (k-j) \\, f_{k-j} \\, e_j; \\\\\nl(t) = \\log(t) , \\qquad \n\n  l_k \n = \\frac{1}{f_0}\\big( f_k - \\frac{1}{k}\\sum_{j=1}^{k-1} j\n    \\, f_{k-j} \\, l_j \\big); \\\\\ns(t) = \\sin(t) , \\qquad \n\n  s_k \n = \\frac{1}{k}\\sum_{j=0}^{k-1} (k-j) \\, f_{k-j} \\, c_j; \\\\\nc(t) = \\cos(t) , \\qquad \n\n  c_k \n = -\\frac{1}{k}\\sum_{j=0}^{k-1} (k-j) \\, f_{k-j} \\, s_j.\n\\end{eqnarray}\n\n\nThe recursion relations for $s(t) = \\sin(f(t))$ and $c(t) = \\cos(f(t))$ depend\non each other; this reflects the fact that they are solutions of a second-order\ndifferential equation. All these relations hold for Taylor expansions in one\nand more independent variables; in the latter case, the Taylor coefficients\n$f_k$ are homogeneous polynomials of degree $k$.\n\n\nReferences\n\n\n[1] W. Tucker, \nValidated Numerics: A Short Introduction to Rigorous Computations\n, Princeton University Press (2011).\n\n\n[2] A. Haro, \nAutomatic differentiation methods in computational dynamical systems: Invariant manifolds and normal forms of vector fields at fixed points\n, \npreprint\n.", 
            "title": "Background"
        }, 
        {
            "location": "/background/#background", 
            "text": "Introduction  TaylorSeries.jl  is an implementation\nof high-order automatic differentiation ,\nas presented in the book by W. Tucker  [1] . The general\nidea is the following.  The Taylor series expansion of an analytical function\n$f(t)$ with  one  independent variable $t$ around $t_0$ can be written as\n\\begin{equation}\nf(t) = f_0 + f_1 (t-t_0) + f_2 (t-t_0)^2 + \\cdots + f_k (t-t_0)^k + \\cdots,\n\\end{equation}\nwhere $f_0=f(t_0)$, and the Taylor coefficients $f_k = f_k(t_0)$ are the\n$k$-th  normalized derivatives  at $t_0$:\n\\begin{equation}\nf_k = \\frac{1}{k!} \\frac{{\\rm d}^k f} {{\\rm d} t^k}(t_0).\n\\end{equation}\nThus, computing the high-order derivatives of $f(x)$ is equivalent to computing\nits Taylor expansion.  In the case of  many  independent variables the same statements hold, though\nthings become more subtle. Following Alex Haro's approach [2] , the Taylor\nexpansion is an infinite sum of  homogeneous polynomials  in the $d$ independent\nvariables $x_1, x_2, \\dots, x_d$, which takes the form\n\\begin{equation}\nf_k (\\mathbf{x_0}) = \\sum_{m_1+\\cdots+m_d = k} f_{m_1,\\dots,m_d}\n(x_1-x_{0_1})^{m_1}\n\\cdots (x_d-x_{0_d})^{m_d} =\n\\sum_{|\\mathbf{m}|=k} f_\\mathbf{m} (\\mathbf{x}-\\mathbf{x_0})^\\mathbf{m}.\n\\end{equation}\nHere, $\\mathbf{m}\\in \\mathbb{N}^d$ is a multi-index of the $k$-th order\nhomogeneous polynomial and $\\mathbf{x}=(x_1,x_2,\\ldots,x_d)$ are the\n$d$ independent variables.  In both cases, a Taylor series expansion can be represented by a\nvector containing\nits coefficients. The difference between the cases of one or more independent variables\nis that the\ncoefficients are real or complex numbers in the former case, but homogeneous polynomials\nin the latter case. This motivates\nthe construction of the  Taylor  and  TaylorN  types, described later.  Arithmetic operations  Arithmetic operations involving Taylor series can be expressed as\noperations on the coefficients:\n\\begin{eqnarray}\n(f(x) \\pm g(x))_k   =   f_k \\pm g_k \\, , \\\\\n\\label{eq:multT}\n(f(x) \\cdot g(x))_k   =   \\sum_{i=0}^k f_i \\, g_{k-i} \\, ,\\\\\n\\Big(\\frac{f(x)}{g(x)}\\Big)_k   =   \\frac{1}{g_0} \\Big[ f_k -\n\\sum_{i=0}^{k-1} \\big(\\frac{f(x)}{g(x)}\\big)_i \\, g_{k-i} \\Big]\\, .\\\\\n\\end{eqnarray}  Equation (\\ref{eq:multT}) corresponds to a convolution.  Elementary functions of polynomials  Consider a function $y(t)$ that satisfies the ordinary differential equation\n$\\dot{y} = f(y)$, $y(t_0)=y_0$, where $t$ is the independent variable.\nWriting $y(t)$ and $f(t)$ as Taylor polynomials of $t$, substituting these in the\ndifferential equation and equating equal powers of\nthe independent variable leads to the recursion relation\n\\begin{equation}\n\\label{eq:rec}\ny_{n+1} = \\frac{f_n}{n+1}.\n\\end{equation}\nEquation (\\ref{eq:rec}), together with the corresponding initial condition, defines a recurrence relation\nfor the Taylor coefficients of $y(t)$ around $t_0$. For more independent\nvariables, using the chain rule for the  radial derivative \nyields recurrence relations for the homogeneous polynomial coefficients\nof the function; see  [2] .  The following are  examples of elementary functions constructed by\nsuch recurrence relations:  \\begin{eqnarray}\np(t)=(f(t))^\\alpha , \\qquad  \n  p_k   = \\frac{1}{k \\, f_0}\\sum_{j=0}^{k-1}\\big( \\alpha(k-j)-j\\big)\n  \\, f_{k-j} \\, p_j; \\\\\ne(t) = \\exp(t) , \\qquad  \n  e_k   = \\frac{1}{k}\\sum_{j=0}^{k-1} (k-j) \\, f_{k-j} \\, e_j; \\\\\nl(t) = \\log(t) , \\qquad  \n  l_k   = \\frac{1}{f_0}\\big( f_k - \\frac{1}{k}\\sum_{j=1}^{k-1} j\n    \\, f_{k-j} \\, l_j \\big); \\\\\ns(t) = \\sin(t) , \\qquad  \n  s_k   = \\frac{1}{k}\\sum_{j=0}^{k-1} (k-j) \\, f_{k-j} \\, c_j; \\\\\nc(t) = \\cos(t) , \\qquad  \n  c_k   = -\\frac{1}{k}\\sum_{j=0}^{k-1} (k-j) \\, f_{k-j} \\, s_j.\n\\end{eqnarray}  The recursion relations for $s(t) = \\sin(f(t))$ and $c(t) = \\cos(f(t))$ depend\non each other; this reflects the fact that they are solutions of a second-order\ndifferential equation. All these relations hold for Taylor expansions in one\nand more independent variables; in the latter case, the Taylor coefficients\n$f_k$ are homogeneous polynomials of degree $k$.  References  [1] W. Tucker,  Validated Numerics: A Short Introduction to Rigorous Computations , Princeton University Press (2011).  [2] A. Haro,  Automatic differentiation methods in computational dynamical systems: Invariant manifolds and normal forms of vector fields at fixed points ,  preprint .", 
            "title": "Background"
        }, 
        {
            "location": "/user_guide/", 
            "text": "MathJax.Hub.Config({\n    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n  });\n  MathJax.Hub.Config({\n    TeX: { extensions: [\"AMSmath.js\", \"AMSsymbols.js\", \"autobold.js\", \"autoload-all.js\"] }\n  });\n  MathJax.Hub.Config({\n    tex2jax: {\n      inlineMath: [['$','$'], ['\\\\(','\\\\)']],\n      processEscapes: true\n    }\n  });\n\n\n\n\n\n\n\n\n\nUser guide\n\n\n\n\nTaylorSeries.jl\n can be thought of as a polynomial algebraic manipulator in one or more\nvariables; these two cases are treated separately.  Three new types are defined,\n\nTaylor1\n, \nHomogeneousPolynomial\n and \nTaylorN\n, which correspond to\nexpansions in one independent variable, homogeneous polynomials of various variables, and the polynomial\nseries in many independent variables, respectively. These types are subtypes\nof \nNumber\n and are defined parametrically.\n\n\nThe package is loaded as usual:\n\n\njulia\n using TaylorSeries\n\n\n\n\nOne variable\n\n\nTaylor expansions in one variable are represented by the \nTaylor1\n type, which\nconsists of a vector of coefficients (field \ncoeffs\n) and the maximum\norder considered for the expansion (field \norder\n). The\ncoefficients are arranged in ascending order with respect to the power of the\nindependent variable, so that\n\ncoeffs[1]\n is the constant term, \ncoeffs[2]\n gives the first order term,\netc. This is a dense representation of the polynomial.\nThe order of the polynomial can be\nomitted in the constructor, which is then fixed from the length of the\nvector of coefficients; otherwise, the maximum\nof the length of the vector of coefficients and the given integer is taken.\n\n\njulia\n Taylor1([1, 2, 3]) # Polynomial of order 2 with coefficients 1, 2, 3\n 1 + 2 t + 3 t\u00b2 + \ud835\udcaa(t\u00b3)\n\njulia\n Taylor1([0.0, 1im]) # Also works with complex numbers\n ( 1.0 im ) t + \ud835\udcaa(t\u00b2)\n\njulia\n affine(a) = a + taylor1_variable(typeof(a),5)  ## a + t of order 5\naffine (generic function with 1 method)\n\njulia\n t = affine(0.0) # Independent variable `t`\n 1.0 t + \ud835\udcaa(t\u2076)\n\n\n\n\nNote that the information about the maximum order considered is displayed\nusing a big-O notation.\n\n\nThe definition of \naffine(a)\n uses the function \ntaylor1_variable\n, which is a\nshortcut to define the independent variable of a Taylor expansion,\nwith a given type and given order. As we show below, this is one of the\neasiest ways to work with the package.\n\n\nThe usual arithmetic operators (\n+\n, \n-\n, \n*\n, \n/\n, \n^\n, \n==\n) have been\nextended to work with the \nTaylor1\n type, including promotions that involve\n\nNumber\ns. The operations return a valid Taylor expansion with the same\nmaximum order; compare the last example below, where this is not possible:\n\n\njulia\n t*(3t+2.5)\n 2.5 t + 3.0 t\u00b2 + \ud835\udcaa(t\u2076)\n\njulia\n 1/(1-t)\n 1.0 + 1.0 t + 1.0 t\u00b2 + 1.0 t\u00b3 + 1.0 t\u2074 + 1.0 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia\n t*(t^2-4)/(t+2)\n - 2.0 t + 1.0 t\u00b2 + \ud835\udcaa(t\u2076)\n\njulia\n tI = im*t\n ( 1.0 im ) t + \ud835\udcaa(t\u2076)\n\njulia\n t^6  # order is 5\n 0.0 + \ud835\udcaa(t\u2076)\n\njulia\n (1-t)^3.2\n 1.0 - 3.2 t + 3.5200000000000005 t\u00b2 - 1.4080000000000004 t\u00b3 + 0.07040000000000009 t\u2074 + 0.011264000000000012 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia\n (1+t)^t\n 1.0 + 1.0 t\u00b2 - 0.5 t\u00b3 + 0.8333333333333333 t\u2074 - 0.75 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia\n t^3.2\nERROR: The 0th order Taylor1 coefficient must be non-zero\nto raise the Taylor1 polynomial to a non-integer exponent\n in ^ at /Users/benet/.julia/v0.3/TaylorSeries/src/utils_Taylor1.jl:280\n\n\n\n\nSeveral elementary functions have been implemented; these compute their\ncoefficients recursively. So far, these functions are \nexp\n, \nlog\n, \nsqrt\n, \nsin\n, \ncos\n\nand \ntan\n;\nmore will be added in the future. Note that this way of obtaining the\nTaylor coefficients is not the \nlaziest\n way, in particular for many independent\nvariables. Yet, it is quite efficient, especially for the integration of\nordinary differential equations, which is among the applications we have in mind.\n\n\njulia\n exp(t)\n 1.0 + 1.0 t + 0.5 t\u00b2 + 0.16666666666666666 t\u00b3 + 0.041666666666666664 t\u2074 + 0.008333333333333333 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia\n log(1-t)\n - 1.0 t - 0.5 t\u00b2 - 0.3333333333333333 t\u00b3 - 0.25 t\u2074 - 0.2 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia\n sqrt(t)\nERROR: First non-vanishing Taylor1 coefficient must correspond\nto an **even power** in order to expand `sqrt` around 0\n in sqrt at /Users/benet/.julia/v0.3/TaylorSeries/src/utils_Taylor1.jl:351\n\njulia\n sqrt(1 + t)\n 1.0 + 0.5 t - 0.125 t\u00b2 + 0.0625 t\u00b3 - 0.0390625 t\u2074 + 0.02734375 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia\n imag(exp(tI)')\n - 1.0 t + 0.16666666666666666 t\u00b3 - 0.008333333333333333 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia\n real(exp(Taylor1([0.0,1im],17))) - cos(Taylor1([0.0,1.0],17)) == 0.0\ntrue\n\njulia\n convert(Taylor1{Rational{Int64}}, exp(t))  # output differes in v0.4\n 1//1 + 1//1 t + 1//2 t\u00b2 + 1//6 t\u00b3 + 1//24 t\u2074 + 1//120 t\u2075 + \ud835\udcaa(t\u2076)\n\n\n\n\nDifferentiating and integrating is straightforward for polynomial expansions in\none variable. The last coefficient of a derivative is set to zero to keep the\nsame order as the original polynomial; for the integral, an\nintegration constant may be set to a different value (the default is zero). The\norder of the resulting polynomial is not changed. The $n$-th ($n \\ge 0$)\nderivative is obtained using \nderiv(a,n)\n, where \na\n is a Taylor series;\nthe default is $n=1$.\n\n\njulia\n diffTaylor(exp(t))\n 1.0 + 1.0 t + 0.5 t\u00b2 + 0.16666666666666666 t\u00b3 + 0.041666666666666664 t\u2074 + \ud835\udcaa(t\u2076)\n\njulia\n integTaylor(exp(t))\n 1.0 t + 0.5 t\u00b2 + 0.16666666666666666 t\u00b3 + 0.041666666666666664 t\u2074 + 0.008333333333333333 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia\n integTaylor( ans, 1.0)\n 1.0 + 0.5 t\u00b2 + 0.16666666666666666 t\u00b3 + 0.041666666666666664 t\u2074 + 0.008333333333333333 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia\n integTaylor( diffTaylor( exp(-t)), 1.0 ) == exp(-t)\ntrue\n\njulia\n deriv( exp(affine(1.0))) == exp(1.0)\ntrue\n\njulia\n deriv( exp(affine(1.0)), 5) == exp(1.0) # Fifth derivative of `exp(1+t)`\ntrue\n\n\n\n\nTo evaluate a Taylor series at a point, Horner's rule is used via the function\n\nevalTaylor(a::Taylor, dt::Number)\n. Here, $dt$ is the increment from\nthe point $t_0$ where the Taylor expansion is calculated, i.e., the series\nis evaluated at $t = t_0 + dt$. Omitting $dt$ corresponds to $dt = 0$.\n\n\njulia\n evaluate(exp(affine(1.0))) - e # exp(t) around t0=1 (order 5), evaluated there (dt=0)\n0.0\n\njulia\n evaluate(exp(t), 1) - e # exp(t) around t0=0 (order 5), evaluated at t=1\n-0.0016151617923783057\n\njulia\n evaluate( exp( taylor1_variable(17) ), 1) - e # exp(t) around t0=0 (order 17), evaluated at t=1\n0.0\n\njulia\n tBig = Taylor1([zero(BigFloat),one(BigFloat)],50) # With BigFloats\n 1e+00 t + \ud835\udcaa(t\u2075\u00b9)\n\njulia\n evaluate( exp(tBig), one(BigFloat) )\n2.718281828459045235360287471352662497757247093699959574966967627723419298053556e+00 with 256 bits of precision\n\njulia\n e - ans\n6.573322999985292556154129119543257102601105719980995128942636339920549561322098e-67 with 256 bits of precision\n\n\n\n\nMany variables\n\n\nA polynomial in $N\n1$ variables can be represented in (at least) two ways:\nAs a vector whose coefficients are homogeneous polynomials of fixed degree, or\nas a vector whose coefficients are polynomials in $N-1$ variables. We have opted\nto implement the first option, which seems to show better performance. An elegant\n(lazy) implementation of the second representation was discussed on the\n\njulia-users\n list.\n\n\nTaylorN\n is thus constructed as a vector of parameterized homogeneous polynomials\ndefined by the type \nHomogeneousPolynomial\n, which in turn is a vector of\ncoefficients of given order (degree). This implementation imposes that the user\nhas to specify the (maximum) order and the number of independent\nvariables, which is done using the \nset_variables(names)\n function.\n\nnames\n is a string consisting of the desired \noutput\n names of the variables,\nseparated by spaces. A vector of the resulting Taylor variables is returned:\n\n\njulia\n x, y = set_variables(\nx y\n)\n2-element Array{TaylorN{Float64},1}:\n  1.0 x + \ud835\udcaa(\u2016x\u2016\u2077)\n  1.0 y + \ud835\udcaa(\u2016x\u2016\u2077)\n\n\n\n\nThe resulting objects are of \nTaylorN{Float64}\n type:\n\n\njulia\n x\n 1.0 x + \ud835\udcaa(\u2016x\u2016\u2077)\n\njulia\n typeof(x)\nTaylorN{Float64} (constructor with 1 method)\n\njulia\n x.order\n6\n\njulia\n x.coeffs\n7-element Array{HomogeneousPolynomial{Float64},1}:\n    0.0\n  1.0 x\n    0.0\n    0.0\n    0.0\n    0.0\n    0.0\n\n\n\n\nThere is an optional \norder\n keyword argument for \nset_variables\n:\n\n\njulia\n set_variables(\nx y\n, order=10)\n2-element Array{TaylorN{Float64},1}:\n  1.0 x + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n  1.0 y + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\n\n\n\nNumbered variables are also available by specifying a single\nvariable name and the optional keyword argument \nnumvars\n:\n\n\njulia\n set_variables(\n\u03b1\n, numvars=3)\n3-element Array{TaylorN{Float64},1}:\n  1.0 \u03b1\u2081 + \ud835\udcaa(\u2016x\u2016\u2077)\n  1.0 \u03b1\u2082 + \ud835\udcaa(\u2016x\u2016\u2077)\n  1.0 \u03b1\u2083 + \ud835\udcaa(\u2016x\u2016\u2077)\n\n\n\n\nThe function \nshow_params_TaylorN()\n displays the current values of the\nparameters:\n\n\njulia\n show_params_TaylorN()\nINFO: Parameters for `TaylorN` and `HomogeneousPolynomial`:\nMaximum order       = 6\nNumber of variables = 3\nVariable names      = UTF8String[\n\u03b1\u2081\n,\n\u03b1\u2082\n,\n\u03b1\u2083\n]\n\n\n\n\nTechnically (internally), changing these parameters defines dictionaries that\ntranslate the position of the coefficients of a \nHomogeneousPolynomial\n\ninto the corresponding\nmulti-variable monomials. Fixing these values from the start is imperative.\n\n\nThe easiest way to construct a \nTaylorN\n object is by defining symbols for\nthe independent variables, as above. Again, the Taylor expansions are implemented\naround 0 for all variables; if the expansion\nis needed around a different value, the trick is a simple translation of\nthe corresponding\nindependent variable $x \\to x+a$.\n\n\nOther ways of constructing \nTaylorN\n polynomials involve using \nHomogeneousPolynomial\n\nobjects directly, which is uncomfortable:\n\n\njulia\n set_variables(\nx\n, numvars=2);\n\njulia\n HomogeneousPolynomial([1,-1])\n 1 x\u2081 - 1 x\u2082\n\njulia\n TaylorN([HomogeneousPolynomial([1,0]), HomogeneousPolynomial([1,2,3])],4)\n 1 x\u2081 + 1 x\u2081\u00b2 + 2 x\u2081 x\u2082 + 3 x\u2082\u00b2 + \ud835\udcaa(\u2016x\u2016\u2075)\n\n\n\n\nAs before, the usual arithmetic operators (\n+\n, \n-\n, \n*\n, \n/\n, \n^\n, \n==\n)\nhave been extended to work with \nTaylorN\n objects, including the appropriate\npromotions to deal with numbers. (Some of the arithmetic operations have\nalso been extended for\n\nHomogeneousPolynomial\n, whenever the result is a \nHomogeneousPolynomial\n;\ndivision, for instance, is not extended.) Also, the elementary functions have been\nimplemented, again by computing their coefficients recursively:\n\n\njulia\n x, y = set_variables(\nx\n, numvars=2, order=10);\n\njulia\n exy = exp(x+y)\n 1.0 + 1.0 x\u2081 + 1.0 x\u2082 + 0.5 x\u2081\u00b2 + 1.0 x\u2081 x\u2082 + 0.5 x\u2082\u00b2 + 0.16666666666666666 x\u2081\u00b3 + 0.5 x\u2081\u00b2 x\u2082 + 0.5 x\u2081 x\u2082\u00b2 + 0.16666666666666666 x\u2082\u00b3 + 0.041666666666666664 x\u2081\u2074 + 0.16666666666666666 x\u2081\u00b3 x\u2082 + 0.25 x\u2081\u00b2 x\u2082\u00b2 + 0.16666666666666666 x\u2081 x\u2082\u00b3 + 0.041666666666666664 x\u2082\u2074 + 0.008333333333333333 x\u2081\u2075 + 0.041666666666666664 x\u2081\u2074 x\u2082 + 0.08333333333333333 x\u2081\u00b3 x\u2082\u00b2 + 0.08333333333333333 x\u2081\u00b2 x\u2082\u00b3 + 0.041666666666666664 x\u2081 x\u2082\u2074 + 0.008333333333333333 x\u2082\u2075 + 0.0013888888888888887 x\u2081\u2076 + 0.008333333333333331 x\u2081\u2075 x\u2082 + 0.020833333333333332 x\u2081\u2074 x\u2082\u00b2 + 0.027777777777777776 x\u2081\u00b3 x\u2082\u00b3 + 0.020833333333333332 x\u2081\u00b2 x\u2082\u2074 + 0.008333333333333331 x\u2081 x\u2082\u2075 + 0.0013888888888888887 x\u2082\u2076 + 0.00019841269841269839 x\u2081\u2077 + 0.0013888888888888885 x\u2081\u2076 x\u2082 + 0.004166666666666666 x\u2081\u2075 x\u2082\u00b2 + 0.006944444444444443 x\u2081\u2074 x\u2082\u00b3 + 0.006944444444444443 x\u2081\u00b3 x\u2082\u2074 + 0.004166666666666666 x\u2081\u00b2 x\u2082\u2075 + 0.0013888888888888885 x\u2081 x\u2082\u2076 + 0.00019841269841269839 x\u2082\u2077 + 2.4801587301587298e-5 x\u2081\u2078 + 0.00019841269841269836 x\u2081\u2077 x\u2082 + 0.0006944444444444443 x\u2081\u2076 x\u2082\u00b2 + 0.0013888888888888887 x\u2081\u2075 x\u2082\u00b3 + 0.0017361111111111108 x\u2081\u2074 x\u2082\u2074 + 0.0013888888888888887 x\u2081\u00b3 x\u2082\u2075 + 0.0006944444444444443 x\u2081\u00b2 x\u2082\u2076 + 0.00019841269841269836 x\u2081 x\u2082\u2077 + 2.4801587301587298e-5 x\u2082\u2078 + 2.7557319223985884e-6 x\u2081\u2079 + 2.4801587301587295e-5 x\u2081\u2078 x\u2082 + 9.920634920634918e-5 x\u2081\u2077 x\u2082\u00b2 + 0.0002314814814814814 x\u2081\u2076 x\u2082\u00b3 + 0.0003472222222222221 x\u2081\u2075 x\u2082\u2074 + 0.0003472222222222221 x\u2081\u2074 x\u2082\u2075 + 0.0002314814814814814 x\u2081\u00b3 x\u2082\u2076 + 9.920634920634918e-5 x\u2081\u00b2 x\u2082\u2077 + 2.4801587301587295e-5 x\u2081 x\u2082\u2078 + 2.7557319223985884e-6 x\u2082\u2079 + 2.7557319223985883e-7 x\u2081\u00b9\u2070 + 2.7557319223985884e-6 x\u2081\u2079 x\u2082 + 1.2400793650793647e-5 x\u2081\u2078 x\u2082\u00b2 + 3.306878306878306e-5 x\u2081\u2077 x\u2082\u00b3 + 5.787037037037036e-5 x\u2081\u2076 x\u2082\u2074 + 6.944444444444443e-5 x\u2081\u2075 x\u2082\u2075 + 5.787037037037036e-5 x\u2081\u2074 x\u2082\u2076 + 3.306878306878306e-5 x\u2081\u00b3 x\u2082\u2077 + 1.2400793650793647e-5 x\u2081\u00b2 x\u2082\u2078 + 2.7557319223985884e-6 x\u2081 x\u2082\u2079 + 2.7557319223985883e-7 x\u2082\u00b9\u2070 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\n\n\n\nThe function \nget_coeff(a,v)\n\ngives the coefficient of \nx\n that corresponds to the monomial\nspecified by the vector of powers \nv\n:\n\n\njulia\n get_coeff(exy, [3,5]) == 1/720\nfalse\n\njulia\n rationalize(get_coeff(exy, [3,5]))\n1//720\n\n\n\n\nPartial differentiation is also implemented for\n\nTaylorN\n objects,\nusing \ndiffTaylor\n; integration is yet to be implemented.\n\n\njulia\n f(x,y) = x^3 + 2x^2 * y - 7x + 2\nf (generic function with 1 method)\n\njulia\n g(x,y) = y - x^4\ng (generic function with 1 method)\n\njulia\n diffTaylor( f(x,y), 1 )   # partial derivative with respect to 1st variable\n - 7.0 + 3.0 x\u2081\u00b2 + 4.0 x\u2081 x\u2082 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia\n diffTaylor( g(x,y), 2 )\n 1.0 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia\n diffTaylor( g(x,y), 3 )   # error, since we are dealing with 2 variables\nERROR: assertion failed: 1 \n= r \n= _params_taylorN.numVars\n in diffTaylor at /Users/benet/.julia/v0.3/TaylorSeries/src/utils_TaylorN.jl:681\n in diffTaylor at /Users/benet/.julia/v0.3/TaylorSeries/src/utils_TaylorN.jl:711\n\n\n\n\nevaluate\n can also be used for \nTaylorN\n objects, using it on vectors of\nnumbers (\nReal\n or \nComplex\n); the length of the vector must coincide with the number\nof independent variables.\n\n\njulia\n evaluate(exy, [.1,.02]) == e^0.12\ntrue\n\n\n\n\nFunctions to compute the gradient, Jacobian and\nHessian have also been implemented. Using the\nfunctions $f(x,y) = x^3 + 2x^2 y - 7 x + 2$ and $g(x,y) = y-x^4$ defined above,\nwe may use \n\u2207\n (\n\\nabla+TAB\n) or \nTaylorSeries.gradient\n; the results are of\ntype \nArray{TaylorN{T},1}\n. To compute the Jacobian or Hessian of a vector field\nevaluated at a point, we use \njacobian\n and \nhessian\n:\n\n\njulia\n f1 = f(x,y)\n 2.0 - 7.0 x\u2081 + 1.0 x\u2081\u00b3 + 2.0 x\u2081\u00b2 x\u2082 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia\n g1 = g(x,y)\n 1.0 x\u2082 - 1.0 x\u2081\u2074 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia\n \u2207(f1)\n2-element Array{TaylorN{Float64},1}:\n  - 7.0 + 3.0 x\u2081\u00b2 + 4.0 x\u2081 x\u2082 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n                      2.0 x\u2081\u00b2 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia\n gradient( g1 )\n2-element Array{TaylorN{Float64},1}:\n  - 4.0 x\u2081\u00b3 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n        1.0 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia\n jacobian([f1,g1], [2,1])\n2x2 Array{Float64,2}:\n  13.0  8.0\n -32.0  1.0\n\njulia\n fg = f1-g1-2*f1*g1\n 2.0 - 7.0 x\u2081 - 5.0 x\u2082 + 14.0 x\u2081 x\u2082 + 1.0 x\u2081\u00b3 + 2.0 x\u2081\u00b2 x\u2082 + 5.0 x\u2081\u2074 - 2.0 x\u2081\u00b3 x\u2082 - 4.0 x\u2081\u00b2 x\u2082\u00b2 - 14.0 x\u2081\u2075 + 2.0 x\u2081\u2077 + 4.0 x\u2081\u2076 x\u2082 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia\n hessian(ans) # hessian at zero\n2x2 Array{Float64,2}:\n  0.0  14.0\n 14.0   0.0\n\n julia\n fg1 = f(x+1.0,y+1.0)-g(x+1.0,y+1.0)-2*f(x+1.0,y+1.0)*g(x+1.0,y+1.0)\n  - 2.0 - 12.0 x\u2081 + 5.0 x\u2082 - 13.0 x\u2081\u00b2 + 20.0 x\u2081 x\u2082 - 4.0 x\u2082\u00b2 + 29.0 x\u2081\u00b3 + 48.0 x\u2081\u00b2 x\u2082 - 8.0 x\u2081 x\u2082\u00b2 + 65.0 x\u2081\u2074 + 78.0 x\u2081\u00b3 x\u2082 - 4.0 x\u2081\u00b2 x\u2082\u00b2 + 52.0 x\u2081\u2075 + 60.0 x\u2081\u2074 x\u2082 + 18.0 x\u2081\u2076 + 24.0 x\u2081\u2075 x\u2082 + 2.0 x\u2081\u2077 + 4.0 x\u2081\u2076 x\u2082 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia\n hessian(fg, [1.0,1.0])\n2x2 Array{Float64,2}:\n -26.0  20.0\n  20.0  -8.0\n\njulia\n ans == hessian(fg1)\ntrue\n\n\n\n\nExamples\n\n\n1. Four-square identity\n\n\nThe first example described below, shows that the four-square identity holds:\n\\begin{eqnarray}\n(a_1+a_2+a_3+a_4)\\cdot(b_1+b_2+b_3+b_4) \n = \n\n     (a_1 b_1 - a_2 b_2 - a_3 b_3 -a_4 b_4)^2 + \\qquad \\nonumber \\\\\n\\label{eq:Euler}\n  \n \n (a_1 b_2 - a_2 b_1 - a_3 b_4 -a_4 b_3)^2 + \\\\\n  \n \n (a_1 b_3 - a_2 b_4 - a_3 b_1 -a_4 b_2)^2 + \\nonumber \\\\\n  \n \n (a_1 b_4 - a_2 b_3 - a_3 b_2 -a_4 b_1)^2, \\nonumber\n\\end{eqnarray}\nas proved by Euler. The code can we found in one of the tests of the package.\n\n\nFirst, we reset the maximum degree of the polynomial to 4, since the RHS\nof the equation\nhas \na priori\n terms of fourth order, and the number of independent variables to\n8.\n\n\njulia\n # Define the variables \u03b1\u2081, ..., \u03b1\u2084, \u03b2\u2081, ..., \u03b2\u2084\n       make_variable(name, index::Int) = string(name, TaylorSeries.subscriptify(index))\nmake_variable (generic function with 1 method)\n\njulia\n variable_names = [make_variable(\n\u03b1\n, i) for i in 1:4]\n4-element Array{UTF8String,1}:\n \n\u03b1\u2081\n\n \n\u03b1\u2082\n\n \n\u03b1\u2083\n\n \n\u03b1\u2084\n\n\njulia\n append!(variable_names, [make_variable(\n\u03b2\n, i) for i in 1:4])\n8-element Array{UTF8String,1}:\n \n\u03b1\u2081\n\n \n\u03b1\u2082\n\n \n\u03b1\u2083\n\n \n\u03b1\u2084\n\n \n\u03b2\u2081\n\n \n\u03b2\u2082\n\n \n\u03b2\u2083\n\n \n\u03b2\u2084\n\n\njulia\n # Create the Taylor objects (order 4, numvars=8)\n       a1, a2, a3, a4, b1, b2, b3, b4 = set_variables(variable_names, order=4);\n\njulia\n a1\n1.0 \u03b1\u2081 + \ud835\udcaa(\u2016x\u2016\u2075)\n\njulia\n b1\n 1.0 \u03b2\u2081 + \ud835\udcaa(\u2016x\u2016\u2075)\n\n\n\n\nNow we define the terms that appear in (\\ref{eq:Euler}):\n\n\njulia\n lhs1 = a1^2 + a2^2 + a3^2 + a4^2 ;\n\njulia\n lhs2 = b1^2 + b2^2 + b3^2 + b4^2 ;\n\njulia\n rhs1 = (a1*b1 - a2*b2 - a3*b3 - a4*b4)^2 ;\n\njulia\n rhs2 = (a1*b2 + a2*b1 + a3*b4 - a4*b3)^2 ;\n\njulia\n rhs3 = (a1*b3 - a2*b4 + a3*b1 + a4*b2)^2 ;\n\njulia\n rhs4 = (a1*b4 + a2*b3 - a3*b2 + a4*b1)^2 ;\n\n\n\n\nFinally, we check that the LHS is indeed equal to the RHS:\n\n\njulia\n lhs = lhs1 * lhs2\n 1.0 \u03b1\u2081\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2081\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2081\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2081\u00b2 \u03b2\u2084\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2084\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2084\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2084\u00b2 + \ud835\udcaa(\u2016x\u2016\u2075)\n\njulia\n rhs = rhs1 + rhs2 + rhs3 + rhs4\n 1.0 \u03b1\u2081\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2081\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2081\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2081\u00b2 \u03b2\u2084\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2084\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2084\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2084\u00b2 + \ud835\udcaa(\u2016x\u2016\u2075)\n\njulia\n lhs == rhs\ntrue\n\n\n\n\nThe identity is thus satisfied. $\\square$.\n\n\n2. Fateman's test\n\n\nRichard J. Fateman, from Berkley, proposed as a stringent test\nof polynomial multiplication\nthe evaluation of $s*(s+1)$, where $s = (1+x+y+z+w)^{20}$. This is\nimplemented in\nthe function \nfateman1\n. We shall also evaluate the form $s^2+s$ in \nfateman2\n,\nwhich involves fewer operations (and makes a fairer comparison to what\nMathematica does). Below we use Julia v0.4, since it is faster than v0.3.\n\n\njulia\n # change number of variables and maxOrder\n       set_variables(\nx\n, numvars=4, order=40);\n\njulia\n function fateman1(degree::Int)\n          T = Int128\n          oneH = HomogeneousPolynomial(one(T), 0)\n          # s = 1 + x + y + z + w\n          s = TaylorN( [oneH, HomogeneousPolynomial([one(T),one(T),one(T),one(T)],1)], degree )\n          s = s^degree  \n          # s is converted to order 2*ndeg\n          s = TaylorN(s, 2*degree)\n\n          s * ( s+TaylorN(oneH, 2*degree) )\n      end\nfateman1 (generic function with 1 method)\n\njulia\n @time f1 = fateman1(0);\nelapsed time: 0.193653166 seconds (8318304 bytes allocated)\n\njulia\n @time f1 = fateman1(20);\n\n\n\n\nThe last instruction shows that we indeed need \nInt128\n arithmetic.\n\n\njulia\n function fateman2(degree::Int)\n           T = Int128\n           oneH = HomogeneousPolynomial(one(T), 0)\n           s = TaylorN( [oneH, HomogeneousPolynomial([one(T),one(T),one(T),one(T)],1)], degree )\n           s = s^degree\n           # s is converted to order 2*ndeg\n           s = TaylorN(s, 2*degree)\n           return s^2 + s\n       end\nfateman2 (generic function with 1 method)\n\njulia\n @time f2 = fateman2(0);\nelapsed time: 0.004246911 seconds (151832 bytes allocated)\n\njulia\n @time f2 = fateman2(20);\nelapsed time: 8.260762578 seconds (1412298112 bytes allocated, 18.28% gc time)\n\njulia\n get_coeff(f2,[1,6,7,20])\n128358585324486316800\n\njulia\n sum(TaylorSeries.sizeTable) # number of distinct monomials\n135751\n\n\n\n\nThe tests above show the necessity of using integers of type \nInt128\n, that\n\nfateman2\n is about twice as fast as \nfateman1\n, and that the series has 135751\nmonomials on 4 variables.\n\n\nWe mention that our implementation of \nfateman2\n (in julia v0.4) is roughly\n1.5 times slower than Mathematica.", 
            "title": "User guide"
        }, 
        {
            "location": "/user_guide/#user-guide", 
            "text": "TaylorSeries.jl  can be thought of as a polynomial algebraic manipulator in one or more\nvariables; these two cases are treated separately.  Three new types are defined, Taylor1 ,  HomogeneousPolynomial  and  TaylorN , which correspond to\nexpansions in one independent variable, homogeneous polynomials of various variables, and the polynomial\nseries in many independent variables, respectively. These types are subtypes\nof  Number  and are defined parametrically.  The package is loaded as usual:  julia  using TaylorSeries", 
            "title": "User guide"
        }, 
        {
            "location": "/user_guide/#one-variable", 
            "text": "Taylor expansions in one variable are represented by the  Taylor1  type, which\nconsists of a vector of coefficients (field  coeffs ) and the maximum\norder considered for the expansion (field  order ). The\ncoefficients are arranged in ascending order with respect to the power of the\nindependent variable, so that coeffs[1]  is the constant term,  coeffs[2]  gives the first order term,\netc. This is a dense representation of the polynomial.\nThe order of the polynomial can be\nomitted in the constructor, which is then fixed from the length of the\nvector of coefficients; otherwise, the maximum\nof the length of the vector of coefficients and the given integer is taken.  julia  Taylor1([1, 2, 3]) # Polynomial of order 2 with coefficients 1, 2, 3\n 1 + 2 t + 3 t\u00b2 + \ud835\udcaa(t\u00b3)\n\njulia  Taylor1([0.0, 1im]) # Also works with complex numbers\n ( 1.0 im ) t + \ud835\udcaa(t\u00b2)\n\njulia  affine(a) = a + taylor1_variable(typeof(a),5)  ## a + t of order 5\naffine (generic function with 1 method)\n\njulia  t = affine(0.0) # Independent variable `t`\n 1.0 t + \ud835\udcaa(t\u2076)  Note that the information about the maximum order considered is displayed\nusing a big-O notation.  The definition of  affine(a)  uses the function  taylor1_variable , which is a\nshortcut to define the independent variable of a Taylor expansion,\nwith a given type and given order. As we show below, this is one of the\neasiest ways to work with the package.  The usual arithmetic operators ( + ,  - ,  * ,  / ,  ^ ,  == ) have been\nextended to work with the  Taylor1  type, including promotions that involve Number s. The operations return a valid Taylor expansion with the same\nmaximum order; compare the last example below, where this is not possible:  julia  t*(3t+2.5)\n 2.5 t + 3.0 t\u00b2 + \ud835\udcaa(t\u2076)\n\njulia  1/(1-t)\n 1.0 + 1.0 t + 1.0 t\u00b2 + 1.0 t\u00b3 + 1.0 t\u2074 + 1.0 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia  t*(t^2-4)/(t+2)\n - 2.0 t + 1.0 t\u00b2 + \ud835\udcaa(t\u2076)\n\njulia  tI = im*t\n ( 1.0 im ) t + \ud835\udcaa(t\u2076)\n\njulia  t^6  # order is 5\n 0.0 + \ud835\udcaa(t\u2076)\n\njulia  (1-t)^3.2\n 1.0 - 3.2 t + 3.5200000000000005 t\u00b2 - 1.4080000000000004 t\u00b3 + 0.07040000000000009 t\u2074 + 0.011264000000000012 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia  (1+t)^t\n 1.0 + 1.0 t\u00b2 - 0.5 t\u00b3 + 0.8333333333333333 t\u2074 - 0.75 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia  t^3.2\nERROR: The 0th order Taylor1 coefficient must be non-zero\nto raise the Taylor1 polynomial to a non-integer exponent\n in ^ at /Users/benet/.julia/v0.3/TaylorSeries/src/utils_Taylor1.jl:280  Several elementary functions have been implemented; these compute their\ncoefficients recursively. So far, these functions are  exp ,  log ,  sqrt ,  sin ,  cos \nand  tan ;\nmore will be added in the future. Note that this way of obtaining the\nTaylor coefficients is not the  laziest  way, in particular for many independent\nvariables. Yet, it is quite efficient, especially for the integration of\nordinary differential equations, which is among the applications we have in mind.  julia  exp(t)\n 1.0 + 1.0 t + 0.5 t\u00b2 + 0.16666666666666666 t\u00b3 + 0.041666666666666664 t\u2074 + 0.008333333333333333 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia  log(1-t)\n - 1.0 t - 0.5 t\u00b2 - 0.3333333333333333 t\u00b3 - 0.25 t\u2074 - 0.2 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia  sqrt(t)\nERROR: First non-vanishing Taylor1 coefficient must correspond\nto an **even power** in order to expand `sqrt` around 0\n in sqrt at /Users/benet/.julia/v0.3/TaylorSeries/src/utils_Taylor1.jl:351\n\njulia  sqrt(1 + t)\n 1.0 + 0.5 t - 0.125 t\u00b2 + 0.0625 t\u00b3 - 0.0390625 t\u2074 + 0.02734375 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia  imag(exp(tI)')\n - 1.0 t + 0.16666666666666666 t\u00b3 - 0.008333333333333333 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia  real(exp(Taylor1([0.0,1im],17))) - cos(Taylor1([0.0,1.0],17)) == 0.0\ntrue\n\njulia  convert(Taylor1{Rational{Int64}}, exp(t))  # output differes in v0.4\n 1//1 + 1//1 t + 1//2 t\u00b2 + 1//6 t\u00b3 + 1//24 t\u2074 + 1//120 t\u2075 + \ud835\udcaa(t\u2076)  Differentiating and integrating is straightforward for polynomial expansions in\none variable. The last coefficient of a derivative is set to zero to keep the\nsame order as the original polynomial; for the integral, an\nintegration constant may be set to a different value (the default is zero). The\norder of the resulting polynomial is not changed. The $n$-th ($n \\ge 0$)\nderivative is obtained using  deriv(a,n) , where  a  is a Taylor series;\nthe default is $n=1$.  julia  diffTaylor(exp(t))\n 1.0 + 1.0 t + 0.5 t\u00b2 + 0.16666666666666666 t\u00b3 + 0.041666666666666664 t\u2074 + \ud835\udcaa(t\u2076)\n\njulia  integTaylor(exp(t))\n 1.0 t + 0.5 t\u00b2 + 0.16666666666666666 t\u00b3 + 0.041666666666666664 t\u2074 + 0.008333333333333333 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia  integTaylor( ans, 1.0)\n 1.0 + 0.5 t\u00b2 + 0.16666666666666666 t\u00b3 + 0.041666666666666664 t\u2074 + 0.008333333333333333 t\u2075 + \ud835\udcaa(t\u2076)\n\njulia  integTaylor( diffTaylor( exp(-t)), 1.0 ) == exp(-t)\ntrue\n\njulia  deriv( exp(affine(1.0))) == exp(1.0)\ntrue\n\njulia  deriv( exp(affine(1.0)), 5) == exp(1.0) # Fifth derivative of `exp(1+t)`\ntrue  To evaluate a Taylor series at a point, Horner's rule is used via the function evalTaylor(a::Taylor, dt::Number) . Here, $dt$ is the increment from\nthe point $t_0$ where the Taylor expansion is calculated, i.e., the series\nis evaluated at $t = t_0 + dt$. Omitting $dt$ corresponds to $dt = 0$.  julia  evaluate(exp(affine(1.0))) - e # exp(t) around t0=1 (order 5), evaluated there (dt=0)\n0.0\n\njulia  evaluate(exp(t), 1) - e # exp(t) around t0=0 (order 5), evaluated at t=1\n-0.0016151617923783057\n\njulia  evaluate( exp( taylor1_variable(17) ), 1) - e # exp(t) around t0=0 (order 17), evaluated at t=1\n0.0\n\njulia  tBig = Taylor1([zero(BigFloat),one(BigFloat)],50) # With BigFloats\n 1e+00 t + \ud835\udcaa(t\u2075\u00b9)\n\njulia  evaluate( exp(tBig), one(BigFloat) )\n2.718281828459045235360287471352662497757247093699959574966967627723419298053556e+00 with 256 bits of precision\n\njulia  e - ans\n6.573322999985292556154129119543257102601105719980995128942636339920549561322098e-67 with 256 bits of precision", 
            "title": "One variable"
        }, 
        {
            "location": "/user_guide/#many-variables", 
            "text": "A polynomial in $N 1$ variables can be represented in (at least) two ways:\nAs a vector whose coefficients are homogeneous polynomials of fixed degree, or\nas a vector whose coefficients are polynomials in $N-1$ variables. We have opted\nto implement the first option, which seems to show better performance. An elegant\n(lazy) implementation of the second representation was discussed on the julia-users  list.  TaylorN  is thus constructed as a vector of parameterized homogeneous polynomials\ndefined by the type  HomogeneousPolynomial , which in turn is a vector of\ncoefficients of given order (degree). This implementation imposes that the user\nhas to specify the (maximum) order and the number of independent\nvariables, which is done using the  set_variables(names)  function. names  is a string consisting of the desired  output  names of the variables,\nseparated by spaces. A vector of the resulting Taylor variables is returned:  julia  x, y = set_variables( x y )\n2-element Array{TaylorN{Float64},1}:\n  1.0 x + \ud835\udcaa(\u2016x\u2016\u2077)\n  1.0 y + \ud835\udcaa(\u2016x\u2016\u2077)  The resulting objects are of  TaylorN{Float64}  type:  julia  x\n 1.0 x + \ud835\udcaa(\u2016x\u2016\u2077)\n\njulia  typeof(x)\nTaylorN{Float64} (constructor with 1 method)\n\njulia  x.order\n6\n\njulia  x.coeffs\n7-element Array{HomogeneousPolynomial{Float64},1}:\n    0.0\n  1.0 x\n    0.0\n    0.0\n    0.0\n    0.0\n    0.0  There is an optional  order  keyword argument for  set_variables :  julia  set_variables( x y , order=10)\n2-element Array{TaylorN{Float64},1}:\n  1.0 x + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n  1.0 y + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)  Numbered variables are also available by specifying a single\nvariable name and the optional keyword argument  numvars :  julia  set_variables( \u03b1 , numvars=3)\n3-element Array{TaylorN{Float64},1}:\n  1.0 \u03b1\u2081 + \ud835\udcaa(\u2016x\u2016\u2077)\n  1.0 \u03b1\u2082 + \ud835\udcaa(\u2016x\u2016\u2077)\n  1.0 \u03b1\u2083 + \ud835\udcaa(\u2016x\u2016\u2077)  The function  show_params_TaylorN()  displays the current values of the\nparameters:  julia  show_params_TaylorN()\nINFO: Parameters for `TaylorN` and `HomogeneousPolynomial`:\nMaximum order       = 6\nNumber of variables = 3\nVariable names      = UTF8String[ \u03b1\u2081 , \u03b1\u2082 , \u03b1\u2083 ]  Technically (internally), changing these parameters defines dictionaries that\ntranslate the position of the coefficients of a  HomogeneousPolynomial \ninto the corresponding\nmulti-variable monomials. Fixing these values from the start is imperative.  The easiest way to construct a  TaylorN  object is by defining symbols for\nthe independent variables, as above. Again, the Taylor expansions are implemented\naround 0 for all variables; if the expansion\nis needed around a different value, the trick is a simple translation of\nthe corresponding\nindependent variable $x \\to x+a$.  Other ways of constructing  TaylorN  polynomials involve using  HomogeneousPolynomial \nobjects directly, which is uncomfortable:  julia  set_variables( x , numvars=2);\n\njulia  HomogeneousPolynomial([1,-1])\n 1 x\u2081 - 1 x\u2082\n\njulia  TaylorN([HomogeneousPolynomial([1,0]), HomogeneousPolynomial([1,2,3])],4)\n 1 x\u2081 + 1 x\u2081\u00b2 + 2 x\u2081 x\u2082 + 3 x\u2082\u00b2 + \ud835\udcaa(\u2016x\u2016\u2075)  As before, the usual arithmetic operators ( + ,  - ,  * ,  / ,  ^ ,  == )\nhave been extended to work with  TaylorN  objects, including the appropriate\npromotions to deal with numbers. (Some of the arithmetic operations have\nalso been extended for HomogeneousPolynomial , whenever the result is a  HomogeneousPolynomial ;\ndivision, for instance, is not extended.) Also, the elementary functions have been\nimplemented, again by computing their coefficients recursively:  julia  x, y = set_variables( x , numvars=2, order=10);\n\njulia  exy = exp(x+y)\n 1.0 + 1.0 x\u2081 + 1.0 x\u2082 + 0.5 x\u2081\u00b2 + 1.0 x\u2081 x\u2082 + 0.5 x\u2082\u00b2 + 0.16666666666666666 x\u2081\u00b3 + 0.5 x\u2081\u00b2 x\u2082 + 0.5 x\u2081 x\u2082\u00b2 + 0.16666666666666666 x\u2082\u00b3 + 0.041666666666666664 x\u2081\u2074 + 0.16666666666666666 x\u2081\u00b3 x\u2082 + 0.25 x\u2081\u00b2 x\u2082\u00b2 + 0.16666666666666666 x\u2081 x\u2082\u00b3 + 0.041666666666666664 x\u2082\u2074 + 0.008333333333333333 x\u2081\u2075 + 0.041666666666666664 x\u2081\u2074 x\u2082 + 0.08333333333333333 x\u2081\u00b3 x\u2082\u00b2 + 0.08333333333333333 x\u2081\u00b2 x\u2082\u00b3 + 0.041666666666666664 x\u2081 x\u2082\u2074 + 0.008333333333333333 x\u2082\u2075 + 0.0013888888888888887 x\u2081\u2076 + 0.008333333333333331 x\u2081\u2075 x\u2082 + 0.020833333333333332 x\u2081\u2074 x\u2082\u00b2 + 0.027777777777777776 x\u2081\u00b3 x\u2082\u00b3 + 0.020833333333333332 x\u2081\u00b2 x\u2082\u2074 + 0.008333333333333331 x\u2081 x\u2082\u2075 + 0.0013888888888888887 x\u2082\u2076 + 0.00019841269841269839 x\u2081\u2077 + 0.0013888888888888885 x\u2081\u2076 x\u2082 + 0.004166666666666666 x\u2081\u2075 x\u2082\u00b2 + 0.006944444444444443 x\u2081\u2074 x\u2082\u00b3 + 0.006944444444444443 x\u2081\u00b3 x\u2082\u2074 + 0.004166666666666666 x\u2081\u00b2 x\u2082\u2075 + 0.0013888888888888885 x\u2081 x\u2082\u2076 + 0.00019841269841269839 x\u2082\u2077 + 2.4801587301587298e-5 x\u2081\u2078 + 0.00019841269841269836 x\u2081\u2077 x\u2082 + 0.0006944444444444443 x\u2081\u2076 x\u2082\u00b2 + 0.0013888888888888887 x\u2081\u2075 x\u2082\u00b3 + 0.0017361111111111108 x\u2081\u2074 x\u2082\u2074 + 0.0013888888888888887 x\u2081\u00b3 x\u2082\u2075 + 0.0006944444444444443 x\u2081\u00b2 x\u2082\u2076 + 0.00019841269841269836 x\u2081 x\u2082\u2077 + 2.4801587301587298e-5 x\u2082\u2078 + 2.7557319223985884e-6 x\u2081\u2079 + 2.4801587301587295e-5 x\u2081\u2078 x\u2082 + 9.920634920634918e-5 x\u2081\u2077 x\u2082\u00b2 + 0.0002314814814814814 x\u2081\u2076 x\u2082\u00b3 + 0.0003472222222222221 x\u2081\u2075 x\u2082\u2074 + 0.0003472222222222221 x\u2081\u2074 x\u2082\u2075 + 0.0002314814814814814 x\u2081\u00b3 x\u2082\u2076 + 9.920634920634918e-5 x\u2081\u00b2 x\u2082\u2077 + 2.4801587301587295e-5 x\u2081 x\u2082\u2078 + 2.7557319223985884e-6 x\u2082\u2079 + 2.7557319223985883e-7 x\u2081\u00b9\u2070 + 2.7557319223985884e-6 x\u2081\u2079 x\u2082 + 1.2400793650793647e-5 x\u2081\u2078 x\u2082\u00b2 + 3.306878306878306e-5 x\u2081\u2077 x\u2082\u00b3 + 5.787037037037036e-5 x\u2081\u2076 x\u2082\u2074 + 6.944444444444443e-5 x\u2081\u2075 x\u2082\u2075 + 5.787037037037036e-5 x\u2081\u2074 x\u2082\u2076 + 3.306878306878306e-5 x\u2081\u00b3 x\u2082\u2077 + 1.2400793650793647e-5 x\u2081\u00b2 x\u2082\u2078 + 2.7557319223985884e-6 x\u2081 x\u2082\u2079 + 2.7557319223985883e-7 x\u2082\u00b9\u2070 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)  The function  get_coeff(a,v) \ngives the coefficient of  x  that corresponds to the monomial\nspecified by the vector of powers  v :  julia  get_coeff(exy, [3,5]) == 1/720\nfalse\n\njulia  rationalize(get_coeff(exy, [3,5]))\n1//720  Partial differentiation is also implemented for TaylorN  objects,\nusing  diffTaylor ; integration is yet to be implemented.  julia  f(x,y) = x^3 + 2x^2 * y - 7x + 2\nf (generic function with 1 method)\n\njulia  g(x,y) = y - x^4\ng (generic function with 1 method)\n\njulia  diffTaylor( f(x,y), 1 )   # partial derivative with respect to 1st variable\n - 7.0 + 3.0 x\u2081\u00b2 + 4.0 x\u2081 x\u2082 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia  diffTaylor( g(x,y), 2 )\n 1.0 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia  diffTaylor( g(x,y), 3 )   # error, since we are dealing with 2 variables\nERROR: assertion failed: 1  = r  = _params_taylorN.numVars\n in diffTaylor at /Users/benet/.julia/v0.3/TaylorSeries/src/utils_TaylorN.jl:681\n in diffTaylor at /Users/benet/.julia/v0.3/TaylorSeries/src/utils_TaylorN.jl:711  evaluate  can also be used for  TaylorN  objects, using it on vectors of\nnumbers ( Real  or  Complex ); the length of the vector must coincide with the number\nof independent variables.  julia  evaluate(exy, [.1,.02]) == e^0.12\ntrue  Functions to compute the gradient, Jacobian and\nHessian have also been implemented. Using the\nfunctions $f(x,y) = x^3 + 2x^2 y - 7 x + 2$ and $g(x,y) = y-x^4$ defined above,\nwe may use  \u2207  ( \\nabla+TAB ) or  TaylorSeries.gradient ; the results are of\ntype  Array{TaylorN{T},1} . To compute the Jacobian or Hessian of a vector field\nevaluated at a point, we use  jacobian  and  hessian :  julia  f1 = f(x,y)\n 2.0 - 7.0 x\u2081 + 1.0 x\u2081\u00b3 + 2.0 x\u2081\u00b2 x\u2082 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia  g1 = g(x,y)\n 1.0 x\u2082 - 1.0 x\u2081\u2074 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia  \u2207(f1)\n2-element Array{TaylorN{Float64},1}:\n  - 7.0 + 3.0 x\u2081\u00b2 + 4.0 x\u2081 x\u2082 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n                      2.0 x\u2081\u00b2 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia  gradient( g1 )\n2-element Array{TaylorN{Float64},1}:\n  - 4.0 x\u2081\u00b3 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n        1.0 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia  jacobian([f1,g1], [2,1])\n2x2 Array{Float64,2}:\n  13.0  8.0\n -32.0  1.0\n\njulia  fg = f1-g1-2*f1*g1\n 2.0 - 7.0 x\u2081 - 5.0 x\u2082 + 14.0 x\u2081 x\u2082 + 1.0 x\u2081\u00b3 + 2.0 x\u2081\u00b2 x\u2082 + 5.0 x\u2081\u2074 - 2.0 x\u2081\u00b3 x\u2082 - 4.0 x\u2081\u00b2 x\u2082\u00b2 - 14.0 x\u2081\u2075 + 2.0 x\u2081\u2077 + 4.0 x\u2081\u2076 x\u2082 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia  hessian(ans) # hessian at zero\n2x2 Array{Float64,2}:\n  0.0  14.0\n 14.0   0.0\n\n julia  fg1 = f(x+1.0,y+1.0)-g(x+1.0,y+1.0)-2*f(x+1.0,y+1.0)*g(x+1.0,y+1.0)\n  - 2.0 - 12.0 x\u2081 + 5.0 x\u2082 - 13.0 x\u2081\u00b2 + 20.0 x\u2081 x\u2082 - 4.0 x\u2082\u00b2 + 29.0 x\u2081\u00b3 + 48.0 x\u2081\u00b2 x\u2082 - 8.0 x\u2081 x\u2082\u00b2 + 65.0 x\u2081\u2074 + 78.0 x\u2081\u00b3 x\u2082 - 4.0 x\u2081\u00b2 x\u2082\u00b2 + 52.0 x\u2081\u2075 + 60.0 x\u2081\u2074 x\u2082 + 18.0 x\u2081\u2076 + 24.0 x\u2081\u2075 x\u2082 + 2.0 x\u2081\u2077 + 4.0 x\u2081\u2076 x\u2082 + \ud835\udcaa(\u2016x\u2016\u00b9\u00b9)\n\njulia  hessian(fg, [1.0,1.0])\n2x2 Array{Float64,2}:\n -26.0  20.0\n  20.0  -8.0\n\njulia  ans == hessian(fg1)\ntrue", 
            "title": "Many variables"
        }, 
        {
            "location": "/user_guide/#examples", 
            "text": "1. Four-square identity  The first example described below, shows that the four-square identity holds:\n\\begin{eqnarray}\n(a_1+a_2+a_3+a_4)\\cdot(b_1+b_2+b_3+b_4)   =  \n     (a_1 b_1 - a_2 b_2 - a_3 b_3 -a_4 b_4)^2 + \\qquad \\nonumber \\\\\n\\label{eq:Euler}\n      (a_1 b_2 - a_2 b_1 - a_3 b_4 -a_4 b_3)^2 + \\\\\n      (a_1 b_3 - a_2 b_4 - a_3 b_1 -a_4 b_2)^2 + \\nonumber \\\\\n      (a_1 b_4 - a_2 b_3 - a_3 b_2 -a_4 b_1)^2, \\nonumber\n\\end{eqnarray}\nas proved by Euler. The code can we found in one of the tests of the package.  First, we reset the maximum degree of the polynomial to 4, since the RHS\nof the equation\nhas  a priori  terms of fourth order, and the number of independent variables to\n8.  julia  # Define the variables \u03b1\u2081, ..., \u03b1\u2084, \u03b2\u2081, ..., \u03b2\u2084\n       make_variable(name, index::Int) = string(name, TaylorSeries.subscriptify(index))\nmake_variable (generic function with 1 method)\n\njulia  variable_names = [make_variable( \u03b1 , i) for i in 1:4]\n4-element Array{UTF8String,1}:\n  \u03b1\u2081 \n  \u03b1\u2082 \n  \u03b1\u2083 \n  \u03b1\u2084 \n\njulia  append!(variable_names, [make_variable( \u03b2 , i) for i in 1:4])\n8-element Array{UTF8String,1}:\n  \u03b1\u2081 \n  \u03b1\u2082 \n  \u03b1\u2083 \n  \u03b1\u2084 \n  \u03b2\u2081 \n  \u03b2\u2082 \n  \u03b2\u2083 \n  \u03b2\u2084 \n\njulia  # Create the Taylor objects (order 4, numvars=8)\n       a1, a2, a3, a4, b1, b2, b3, b4 = set_variables(variable_names, order=4);\n\njulia  a1\n1.0 \u03b1\u2081 + \ud835\udcaa(\u2016x\u2016\u2075)\n\njulia  b1\n 1.0 \u03b2\u2081 + \ud835\udcaa(\u2016x\u2016\u2075)  Now we define the terms that appear in (\\ref{eq:Euler}):  julia  lhs1 = a1^2 + a2^2 + a3^2 + a4^2 ;\n\njulia  lhs2 = b1^2 + b2^2 + b3^2 + b4^2 ;\n\njulia  rhs1 = (a1*b1 - a2*b2 - a3*b3 - a4*b4)^2 ;\n\njulia  rhs2 = (a1*b2 + a2*b1 + a3*b4 - a4*b3)^2 ;\n\njulia  rhs3 = (a1*b3 - a2*b4 + a3*b1 + a4*b2)^2 ;\n\njulia  rhs4 = (a1*b4 + a2*b3 - a3*b2 + a4*b1)^2 ;  Finally, we check that the LHS is indeed equal to the RHS:  julia  lhs = lhs1 * lhs2\n 1.0 \u03b1\u2081\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2081\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2081\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2081\u00b2 \u03b2\u2084\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2084\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2084\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2084\u00b2 + \ud835\udcaa(\u2016x\u2016\u2075)\n\njulia  rhs = rhs1 + rhs2 + rhs3 + rhs4\n 1.0 \u03b1\u2081\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2081\u00b2 + 1.0 \u03b1\u2081\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2082\u00b2 + 1.0 \u03b1\u2081\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2083\u00b2 + 1.0 \u03b1\u2081\u00b2 \u03b2\u2084\u00b2 + 1.0 \u03b1\u2082\u00b2 \u03b2\u2084\u00b2 + 1.0 \u03b1\u2083\u00b2 \u03b2\u2084\u00b2 + 1.0 \u03b1\u2084\u00b2 \u03b2\u2084\u00b2 + \ud835\udcaa(\u2016x\u2016\u2075)\n\njulia  lhs == rhs\ntrue  The identity is thus satisfied. $\\square$.  2. Fateman's test  Richard J. Fateman, from Berkley, proposed as a stringent test\nof polynomial multiplication\nthe evaluation of $s*(s+1)$, where $s = (1+x+y+z+w)^{20}$. This is\nimplemented in\nthe function  fateman1 . We shall also evaluate the form $s^2+s$ in  fateman2 ,\nwhich involves fewer operations (and makes a fairer comparison to what\nMathematica does). Below we use Julia v0.4, since it is faster than v0.3.  julia  # change number of variables and maxOrder\n       set_variables( x , numvars=4, order=40);\n\njulia  function fateman1(degree::Int)\n          T = Int128\n          oneH = HomogeneousPolynomial(one(T), 0)\n          # s = 1 + x + y + z + w\n          s = TaylorN( [oneH, HomogeneousPolynomial([one(T),one(T),one(T),one(T)],1)], degree )\n          s = s^degree  \n          # s is converted to order 2*ndeg\n          s = TaylorN(s, 2*degree)\n\n          s * ( s+TaylorN(oneH, 2*degree) )\n      end\nfateman1 (generic function with 1 method)\n\njulia  @time f1 = fateman1(0);\nelapsed time: 0.193653166 seconds (8318304 bytes allocated)\n\njulia  @time f1 = fateman1(20);  The last instruction shows that we indeed need  Int128  arithmetic.  julia  function fateman2(degree::Int)\n           T = Int128\n           oneH = HomogeneousPolynomial(one(T), 0)\n           s = TaylorN( [oneH, HomogeneousPolynomial([one(T),one(T),one(T),one(T)],1)], degree )\n           s = s^degree\n           # s is converted to order 2*ndeg\n           s = TaylorN(s, 2*degree)\n           return s^2 + s\n       end\nfateman2 (generic function with 1 method)\n\njulia  @time f2 = fateman2(0);\nelapsed time: 0.004246911 seconds (151832 bytes allocated)\n\njulia  @time f2 = fateman2(20);\nelapsed time: 8.260762578 seconds (1412298112 bytes allocated, 18.28% gc time)\n\njulia  get_coeff(f2,[1,6,7,20])\n128358585324486316800\n\njulia  sum(TaylorSeries.sizeTable) # number of distinct monomials\n135751  The tests above show the necessity of using integers of type  Int128 , that fateman2  is about twice as fast as  fateman1 , and that the series has 135751\nmonomials on 4 variables.  We mention that our implementation of  fateman2  (in julia v0.4) is roughly\n1.5 times slower than Mathematica.", 
            "title": "Examples"
        }
    ]
}